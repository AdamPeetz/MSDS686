{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z1BMmhrW4-VF"
   },
   "source": [
    "# A tutorial introduction into deep learning with Keras and Tensorflow.  We will use the MNIST dataset which is the 'Hello world' problem of deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfjjxqk-4-VY"
   },
   "source": [
    "I always like to start my jupternotebooks with this code because it fits the display window to my screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "oq3zQaj94-Vf",
    "outputId": "0375de18-9654-4b22-89c1-f6e04c750bc0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTIiJaMH4-We"
   },
   "source": [
    "### This tutrial was adapted from Deep Learning with Python Chapter 2 Chollet, F. (2017). Deep Learning with Python (1st ed.). Greenwich, CT, USA: Manning Publications Co."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7J8caRE4-Wv"
   },
   "source": [
    "Start with some definitions.\n",
    "Numerical data in an array are called tensors.  https://en.wikipedia.org/wiki/Tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYhqLSfB4-W5"
   },
   "source": [
    "Scalars are 0 dimensional tensors (a single digit). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "sq1dfmTjXx1r",
    "outputId": "ddf0f915-fadf-4d87-cb65-308a51296a37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of x is 12\n",
      "The dimension of this tensor is 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array(12)\n",
    "print('The value of x is', x)\n",
    "print('The dimension of this tensor is', x.ndim) # 0 dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yd6j127g4-Xg"
   },
   "source": [
    "A 1 dimensional tensor is also called a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "_iWxjAcgYF2H",
    "outputId": "3d2447cf-76b2-4034-d6a1-dcd12ccf55ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of x is [12  1  2  3]\n",
      "The dimention of this tensor is 1\n"
     ]
    }
   ],
   "source": [
    "x = np.array([12, 1, 2, 3]) #create a vector\n",
    "print('The value of x is', x)\n",
    "print('The dimention of this tensor is', x.ndim) # 1 dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZnkKqX74-YS"
   },
   "source": [
    "A 2 dimensional tensor is also called a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "kw6vcniRYMga",
    "outputId": "f4ee5bc7-965a-4d85-b493-c50238941adb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of x is [[12  1  2  3]\n",
      " [ 5  6  7  8]\n",
      " [10 11 12 12]]\n",
      "The dimension of this tensor is 2\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[12, 1, 2, 3],\n",
    "              [5, 6, 7, 8,],\n",
    "              [10, 11, 12, 12]])\n",
    "print('The value of x is', x) # Print the 3 x 4 matrix\n",
    "print('The dimension of this tensor is', x.ndim) # 2 dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JDXBkNgF4-ZH"
   },
   "source": [
    "We can create n dimensional tensors easily, although they become difficult to visualize.\n",
    "This 3D tensor is like a cube of data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "7unoEvdhYbYR",
    "outputId": "35ecfa50-0dd5-4794-d417-c55fb2708995"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of x is\n",
      "[[[12  1  2  3]\n",
      "  [ 5  6  7  8]\n",
      "  [10 11 12 12]]\n",
      "\n",
      " [[ 2  2  2  2]\n",
      "  [ 3  3  3  3]\n",
      "  [ 4  4  4  4]]\n",
      "\n",
      " [[ 5  5  5  5]\n",
      "  [ 6  6  6  6]\n",
      "  [ 7  7  7  7]]]\n",
      "The dimension of this tensor is 3\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[[12, 1, 2, 3],\n",
    "               [5, 6, 7, 8,],\n",
    "               [10, 11, 12, 12]],\n",
    "              [[2, 2, 2, 2,],\n",
    "               [3,3,3,3],\n",
    "               [4,4,4,4]],\n",
    "              [[5,5,5,5],\n",
    "               [6,6,6,6],\n",
    "               [7,7,7,7]]])\n",
    "print('The value of x is')\n",
    "print(x)\n",
    "print('The dimension of this tensor is', x.ndim) # 3 dimensional array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QrNkyOM4-Z0"
   },
   "source": [
    "#### Reshaping tensors is important concept to understand.  We can reshape a tensor as long as it has the same number of coefficients as the initial tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 752
    },
    "id": "x5jul5ly4-Z6",
    "outputId": "32959098-e2c0-4060-f79e-f121b612ae36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12]\n",
      " [ 1]\n",
      " [ 2]\n",
      " [ 3]\n",
      " [ 5]\n",
      " [ 6]\n",
      " [ 7]\n",
      " [ 8]\n",
      " [10]\n",
      " [11]\n",
      " [12]\n",
      " [12]\n",
      " [ 2]\n",
      " [ 2]\n",
      " [ 2]\n",
      " [ 2]\n",
      " [ 3]\n",
      " [ 3]\n",
      " [ 3]\n",
      " [ 3]\n",
      " [ 4]\n",
      " [ 4]\n",
      " [ 4]\n",
      " [ 4]\n",
      " [ 5]\n",
      " [ 5]\n",
      " [ 5]\n",
      " [ 5]\n",
      " [ 6]\n",
      " [ 6]\n",
      " [ 6]\n",
      " [ 6]\n",
      " [ 7]\n",
      " [ 7]\n",
      " [ 7]\n",
      " [ 7]]\n",
      "[[12  1  2  3  5  6  7  8 10]\n",
      " [11 12 12  2  2  2  2  3  3]\n",
      " [ 3  3  4  4  4  4  5  5  5]\n",
      " [ 5  6  6  6  6  7  7  7  7]]\n"
     ]
    }
   ],
   "source": [
    "x = x.reshape(3*3*4,1)\n",
    "print(x)\n",
    "x = x.reshape(4, 3*3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihVQabEo4-aS"
   },
   "source": [
    "##### Tensors have three atributes: number of axis (dimensions), shape (length of each axis), and data type (typically we will use float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CUA1N4pS4-aY"
   },
   "source": [
    "Load the MNIST library which is part of Keras.  MNIST stands for Modified National Institute of Technology. https://en.wikipedia.org/wiki/MNIST_database. It is a collection of 60,000 training and 10,000 test images of the digits 0-9. https://keras.io/datasets/. We will build a deep learning nerual net model to classify the 10 digits. This is the 'Hello World' problem of deep learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1AG-iMB8P3DZ"
   },
   "outputs": [],
   "source": [
    "# From the tensorflow data sets import MNIST\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "5Efu6_zaQKtQ",
    "outputId": "b469ac37-38b7-43d0-8521-49819b011a79"
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels),(test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ZYu3aOo4Qn9R",
    "outputId": "769f97fb-a084-4a99-e885-cb0531b87883"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape #60,000 images that are 28 pixles by 28 pixles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "73Jt87YRZBXe",
    "outputId": "2a7cc881-8643-4066-ea63-61b49e3aa246"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.ndim #3D tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "q_fgMe2h4-bm",
    "outputId": "c3aeaf92-3a62-4673-b127-1b96415f3d0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum value in the array is 255\n",
      "he minimum value in the array is 0\n"
     ]
    }
   ],
   "source": [
    "print('The maximum value in the array is', train_images.max()) # The maximum value in the array is 255\n",
    "print('he minimum value in the array is', train_images.min()) # The minimum value in the array is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ACNHKDMhZMtH"
   },
   "outputs": [],
   "source": [
    "# Get the shape, dimensions, max and min value of the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "LvcS2anBQ8cd",
    "outputId": "820a862a-593c-4dcd-9d8a-a64b2aaf46ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test image shape: (10000, 28, 28)\n",
      "number of dimensions: 3\n",
      "maximum value 255\n",
      "minimum value: 0\n"
     ]
    }
   ],
   "source": [
    "print('test image shape:', test_images.shape)\n",
    "print('number of dimensions:', test_images.ndim)\n",
    "print('maximum value', test_images.max())\n",
    "print('minimum value:', test_images.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lAWThxtY4-co"
   },
   "source": [
    "In general the first axis in a tensor is the samples, the second axis is height, the third axis is the width, and the fourth is color channels (RGB = 3 & BW = 1)\n",
    "So image data will be a 4D tensor [samples, height, width, channels] the MNIST data is 3D bacause the color channel is black and white and thus = 1\n",
    "Video data will be a 5D tensor [samples, frames, height, width, channels]. By convention, time series data will be placed on the secod axis when present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kavsqyWG4-cZ"
   },
   "source": [
    "Let's view one of the images.  We need to import matplotlib to view the digits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "jwEiakpiZXnf"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "HvYknn0hZf51",
    "outputId": "889f44ad-6b4c-416c-df49-7a12b477db00"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit = train_images[4] # Select the fouth sample.\n",
    "plt.imshow(digit, cmap=plt.cm.binary) # Show the sample.  cmap is the color map.  We will keep it black and white (binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "gSBcnrgsRPJ3"
   },
   "outputs": [],
   "source": [
    "# Import models and layers from tensorflow \n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "w8lxhcrHRV0x"
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(512, activation='relu',input_shape=(28 * 28,)))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "TcixP8_xR5j7"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "cEeckA5ESIMB",
    "outputId": "ee76ea3d-980e-4616-fd91-6ca038b01e6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "train_images =  train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32')/train_images.max()\n",
    "\n",
    "print(train_images.ndim)\n",
    "\n",
    "test_images =  test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32')/test_images.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "Crqw7E-x4-eh",
    "outputId": "14f50c1a-cd40-4b1a-f812-dbba438fd30b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18906d87d90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAANo0lEQVR4nO3db6hc9Z3H8c9Ht4qkDZrNjRvTsLfWPNiwsmkZzIJas5RNVJRYQTFoiBBMH0RIoeJKVBpERZdNS8VNIV1NU+0ahdY/D2RjCMXYJyGjZDXZsGuU2KYJ5kaRpuKfjX73wT1ZrvHOb27m3xn9vl9wmZnznTPny+gnZ2Z+55yfI0IAvvxOq7sBAINB2IEkCDuQBGEHkiDsQBJ/MciNzZw5M0ZHRwe5SSCVAwcO6OjRo56s1lXYbV8u6aeSTpf0bxHxQOn5o6Ojajab3WwSQEGj0WhZ6/hjvO3TJf2rpCskzZe0zPb8Tl8PQH918539Ikn7I+LNiPhY0hZJS3vTFoBe6ybscyT9YcLjg9Wyz7C9ynbTdnNsbKyLzQHoRjdhn+xHgM8dexsRGyOiERGNkZGRLjYHoBvdhP2gpLkTHn9d0qHu2gHQL92EfZekeba/YfsMSTdIeq43bQHotY6H3iLiuO1bJW3V+NDboxGxt2edAeiprsbZI+J5Sc/3qBcAfcThskAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkupqy2fYBScckfSLpeEQ0etEUgN7rKuyVf4iIoz14HQB9xMd4IIluwx6SXrD9su1Vkz3B9irbTdvNsbGxLjcHoFPdhv3iiPi2pCskrbb9nZOfEBEbI6IREY2RkZEuNwegU12FPSIOVbdHJD0t6aJeNAWg9zoOu+1ptr924r6kxZL29KoxAL3Vza/x50p62vaJ1/n3iPiPnnQFoOc6DntEvCnp73rYC4A+YugNSIKwA0kQdiAJwg4kQdiBJHpxIgyG2M6dO4v1xx57rFjfsWNHsb5nT+eHVqxfv75YP++884r1l156qVhfvnx5y9rChQuL634ZsWcHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQYZ/8SePLJJ1vW1qxZU1y33aXCIqJYX7RoUbF+9Gjra5HedtttxXXbaddbadtbtmzpattfROzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtmHwPHjx4v1Xbt2Feu33HJLy9r7779fXPeyyy4r1u++++5i/ZJLLinWP/roo5a166+/vrju1q1bi/V2Gg0mFZ6IPTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJME4+xB4/PHHi/WVK1d2/NqLFy8u1kvnwkvS9OnTO952u9fvdhx97ty5xfqKFSu6ev0vm7Z7dtuP2j5ie8+EZTNsb7P9enV7Tn/bBNCtqXyM/4Wky09adoek7RExT9L26jGAIdY27BGxQ9K7Jy1eKmlzdX+zpGt62xaAXuv0B7pzI+KwJFW3s1o90fYq203bzXbXOwPQP33/NT4iNkZEIyIaIyMj/d4cgBY6DfvbtmdLUnV7pHctAeiHTsP+nKQT4xorJD3bm3YA9EvbcXbbT0haJGmm7YOSfiTpAUlP2V4p6feSrutnk190d911V7F+//33F+u2i/XVq1e3rN17773FdbsdR2/nvvvu69trP/TQQ8U6Xxs/q23YI2JZi9J3e9wLgD7icFkgCcIOJEHYgSQIO5AEYQeS4BTXHrjnnnuK9XZDa2eeeWaxvmTJkmL9wQcfbFk766yziuu28+GHHxbrL7zwQrH+1ltvtay1m3K53WWsly5dWqzjs9izA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASjLNP0XvvvdeytmHDhuK67U5RbTeO/swzzxTr3di/f3+xfuONNxbrzWaz421fd135zOjbb7+949fG57FnB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkGGefoo8//rhlrdtprdpdEvnIkfIcHJs2bWpZe/bZ8iX99+7dW6wfO3asWG93DMFpp7Xen9x0003FdadNm1as49SwZweSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhnn6IzzjijZW3WrFnFdduNk4+Ojhbr7cayuzFnzpxivd2UzocOHSrWZ86c2bJ29dVXF9dFb7Xds9t+1PYR23smLFtn+4+2d1d/V/a3TQDdmsrH+F9IunyS5T+JiAXV3/O9bQtAr7UNe0TskPTuAHoB0Efd/EB3q+1Xq4/557R6ku1Vtpu2m90eQw6gc52G/WeSvilpgaTDkta3emJEbIyIRkQ0RkZGOtwcgG51FPaIeDsiPomITyX9XNJFvW0LQK91FHbbsyc8/J6kPa2eC2A4tB1nt/2EpEWSZto+KOlHkhbZXiApJB2Q9P3+tTgczj777Ja1dtd1v+qqq4r1d955p1i/4IILivXSPOU333xzcd0ZM2YU6zfccEOx3m6cvd36GJy2YY+IZZMsfqQPvQDoIw6XBZIg7EAShB1IgrADSRB2IAlOce2BhQsXFuvDfJjwjh07ivUXX3yxWG93+u35559/yj2hP9izA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASjLMn98EHHxTr7cbR29U5xXV4sGcHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQYZ09uyZIldbeAAWHPDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMM6e3NatW+tuAQPSds9ue67t39reZ3uv7TXV8hm2t9l+vbo9p//tAujUVD7GH5f0w4j4G0l/L2m17fmS7pC0PSLmSdpePQYwpNqGPSIOR8Qr1f1jkvZJmiNpqaTN1dM2S7qmTz0C6IFT+oHO9qikb0naKenciDgsjf+DIGlWi3VW2W7abg7znGfAl92Uw277q5J+LekHEfGnqa4XERsjohERjZGRkU56BNADUwq77a9oPOi/iojfVIvftj27qs+WdKQ/LQLohbZDbx6/VvAjkvZFxI8nlJ6TtELSA9Xts33pEH31xhtv1N0CBmQq4+wXS1ou6TXbu6tlazUe8qdsr5T0e0nX9aVDAD3RNuwR8TtJrWYC+G5v2wHQLxwuCyRB2IEkCDuQBGEHkiDsQBKc4prcpZdeWqxHxIA6Qb+xZweSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhnT+7CCy8s1ufNm1estzsfvlTnykWDxZ4dSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgnB1Fa9euLdZXrlzZ8foPP/xwcd358+cX6zg17NmBJAg7kARhB5Ig7EAShB1IgrADSRB2IImpzM8+V9IvJf2VpE8lbYyIn9peJ+kWSWPVU9dGxPP9ahT1uPbaa4v1LVu2FOvbtm1rWVu3bl1x3U2bNhXr06ZNK9bxWVM5qOa4pB9GxCu2vybpZdsn/gv+JCL+pX/tAeiVqczPfljS4er+Mdv7JM3pd2MAeuuUvrPbHpX0LUk7q0W32n7V9qO2z2mxzirbTdvNsbGxyZ4CYACmHHbbX5X0a0k/iIg/SfqZpG9KWqDxPf/6ydaLiI0R0YiIBtccA+ozpbDb/orGg/6riPiNJEXE2xHxSUR8Kunnki7qX5sAutU27LYt6RFJ+yLixxOWz57wtO9J2tP79gD0ylR+jb9Y0nJJr9neXS1bK2mZ7QWSQtIBSd/vQ3+o2fTp04v1p556qli/8847W9Y2bNhQXLfd0BynwJ6aqfwa/ztJnqTEmDrwBcIRdEAShB1IgrADSRB2IAnCDiRB2IEkHBED21ij0Yhmszmw7QHZNBoNNZvNyYbK2bMDWRB2IAnCDiRB2IEkCDuQBGEHkiDsQBIDHWe3PSbprQmLZko6OrAGTs2w9jasfUn01qle9vbXETHp9d8GGvbPbdxuRkSjtgYKhrW3Ye1LordODao3PsYDSRB2IIm6w76x5u2XDGtvw9qXRG+dGkhvtX5nBzA4de/ZAQwIYQeSqCXsti+3/d+299u+o44eWrF9wPZrtnfbrvXk+2oOvSO290xYNsP2NtuvV7eTzrFXU2/rbP+xeu92276ypt7m2v6t7X2299peUy2v9b0r9DWQ923g39ltny7pfyT9o6SDknZJWhYR/zXQRlqwfUBSIyJqPwDD9nck/VnSLyPib6tl/yzp3Yh4oPqH8pyI+Kch6W2dpD/XPY13NVvR7InTjEu6RtLNqvG9K/R1vQbwvtWxZ79I0v6IeDMiPpa0RdLSGvoYehGxQ9K7Jy1eKmlzdX+zxv9nGbgWvQ2FiDgcEa9U949JOjHNeK3vXaGvgagj7HMk/WHC44MarvneQ9ILtl+2varuZiZxbkQclsb/55E0q+Z+TtZ2Gu9BOmma8aF57zqZ/rxbdYR9sutjDdP438UR8W1JV0haXX1cxdRMaRrvQZlkmvGh0On0592qI+wHJc2d8Pjrkg7V0MekIuJQdXtE0tMavqmo3z4xg251e6Tmfv7fME3jPdk04xqC967O6c/rCPsuSfNsf8P2GZJukPRcDX18ju1p1Q8nsj1N0mIN31TUz0laUd1fIenZGnv5jGGZxrvVNOOq+b2rffrziBj4n6QrNf6L/BuS7qyjhxZ9nS/pP6u/vXX3JukJjX+s+1+NfyJaKekvJW2X9Hp1O2OIentM0muSXtV4sGbX1NslGv9q+Kqk3dXflXW/d4W+BvK+cbgskARH0AFJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEv8HQhse1dlg+nEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images.reshape((60000,28,28))[4], cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "bw_1wSzI4-ex",
    "outputId": "b41f64f5-6d86-4970-f8a7-c7ba99201288"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train image shape: (60000, 784)\n",
      "number of dimensions: 2\n",
      "maximum value 1.0\n",
      "minimum value: 0.0\n"
     ]
    }
   ],
   "source": [
    "print('train image shape:', train_images.shape)\n",
    "print('number of dimensions:', train_images.ndim)\n",
    "print('maximum value', train_images.max())\n",
    "print('minimum value:', train_images.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "44PHpAPRUVyV"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "zeczsZHUVDQx"
   },
   "outputs": [],
   "source": [
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "id": "w90ZrgWhVPC1",
    "outputId": "b423318e-656b-4353-f686-abcca13fbfd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.2627 - accuracy: 0.9251\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1057 - accuracy: 0.9694\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0692 - accuracy: 0.9798\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0495 - accuracy: 0.9855\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0357 - accuracy: 0.9891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18904b4dd00>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs = 5, batch_size = 120) \n",
    "# Batch size is how many images to process at once. Epoch is how many times to repeat the analysis.  Each epoch performs 500 gradient updates (60,000/120 = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "OHqqd_YYVdz3",
    "outputId": "177ef72e-0444-460e-fa68-466aaa8158bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 646us/step - loss: 0.0641 - accuracy: 0.9796\n",
      "test_acc: 0.9796000123023987\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIRCQyZ2F24o"
   },
   "source": [
    "# Your Turn\n",
    "####  Build 3 different models with activations 'relu', 'tanh', and 'sigmoid'.  The last activation must be 'softmax' since we have a multiclass problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "KgHnMI6T4-f6"
   },
   "outputs": [],
   "source": [
    "relu_model = models.Sequential()\n",
    "relu_model.add(layers.Dense(512, activation='relu',input_shape=(28 * 28,)))\n",
    "relu_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "tanh_model = models.Sequential()\n",
    "tanh_model.add(layers.Dense(512, activation='tanh',input_shape=(28 * 28,)))\n",
    "tanh_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "sigmoid_model = models.Sequential()\n",
    "sigmoid_model.add(layers.Dense(512, activation='sigmoid',input_shape=(28 * 28,)))\n",
    "sigmoid_model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BnUDSgXk4-gE"
   },
   "source": [
    "#### Compile your model.  Use categorical_crossentropyy since this problem is a multiclassification problem. Metrics will be 'accuracy' and optimizer will be 'adam'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "FhHGydeC4-gH"
   },
   "outputs": [],
   "source": [
    "relu_model.compile(optimizer = 'adam',\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy'])\n",
    "\n",
    "tanh_model.compile(optimizer = 'adam',\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy'])\n",
    "\n",
    "sigmoid_model.compile(optimizer = 'adam',\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7uSP2vm4-gR"
   },
   "source": [
    "#### Fit the models with epochs = 5 and  batch_size = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Y9qFLRMA4-gT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2755 - accuracy: 0.9225\n",
      "Epoch 2/5\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.1122 - accuracy: 0.9678\n",
      "Epoch 3/5\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0730 - accuracy: 0.9789\n",
      "Epoch 4/5\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0525 - accuracy: 0.9847\n",
      "Epoch 5/5\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0389 - accuracy: 0.9887\n",
      "Epoch 1/5\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.3338 - accuracy: 0.9039\n",
      "Epoch 2/5\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.1887 - accuracy: 0.9458\n",
      "Epoch 3/5\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.1300 - accuracy: 0.9622\n",
      "Epoch 4/5\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0951 - accuracy: 0.9729\n",
      "Epoch 5/5\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.0735 - accuracy: 0.9787\n",
      "Epoch 1/5\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.4762 - accuracy: 0.8729\n",
      "Epoch 2/5\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2590 - accuracy: 0.9253\n",
      "Epoch 3/5\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.2065 - accuracy: 0.9405\n",
      "Epoch 4/5\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.1688 - accuracy: 0.9513\n",
      "Epoch 5/5\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.1401 - accuracy: 0.9598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1890f144a90>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu_model.fit(train_images, train_labels, epochs = 5, batch_size = 150)\n",
    "tanh_model.fit(train_images, train_labels, epochs = 5, batch_size = 150)\n",
    "sigmoid_model.fit(train_images, train_labels, epochs = 5, batch_size = 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WB4RPCz54-gb"
   },
   "source": [
    "#### Test the accuracy of the model on the test images and test labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "W7V6DjwV4-gc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 657us/step - loss: 0.0660 - accuracy: 0.9804\n",
      "relu_test_acc: 0.980400025844574\n",
      "313/313 [==============================] - 0s 596us/step - loss: 0.0872 - accuracy: 0.9737\n",
      "tanh_test_acc: 0.9736999869346619\n",
      "313/313 [==============================] - 0s 701us/step - loss: 0.1357 - accuracy: 0.9597\n",
      "sigmoid_model_test_acc: 0.9596999883651733\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = relu_model.evaluate(test_images, test_labels)\n",
    "print('relu_test_acc:', test_acc)\n",
    "\n",
    "test_loss, test_acc = tanh_model.evaluate(test_images, test_labels)\n",
    "print('tanh_test_acc:', test_acc)\n",
    "\n",
    "test_loss, test_acc = sigmoid_model.evaluate(test_images, test_labels)\n",
    "print('sigmoid_model_test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DbR0ds5G4-gm"
   },
   "source": [
    "#### which activation gave the highest accuracy?\n",
    "\n",
    "The ReLU activation model had the best performance, achieving 98.04 precent accuracy on the test set. The second highest model was Tanh, achieving 97.37 percent accuracy. The worst model in the test was the Sigmoid model, which only achieved 95.97 percent accuracy on the test dataset. These values will change if the test is rerun do to randomness in the initialization and training of the network.\n",
    "<br>\n",
    "<br>\n",
    "ReLU has been shown to outperform Tanh and Sigmoid activation functions in deep learning applications. It is faster to compute than the Sigmoid and Tanh functions. For this reason, it was selected as the activation algorithm for AlexNet. The research team constructing AlexNet stated that its training speed was critical to their success. It allowed them to test multiple deep models in less time. (Krizhevsky, Sutskever, Hinton, 2012)\n",
    "<br>\n",
    "<br>\n",
    "ReLU also overcomes the problem of vanishing gradients in deep neural networks. The math behind the Sigmoid and Tanh functions causes small numbers to be multiplied against each other. As numbers less than one multiply against other numbers less than one they slowly dimmish towards zero. This causes the backpropagation of loss to die out in extremely deep networks and can result in networks converging early on non-optimal solutions. With ReLU, the value of the gradient is either 1 or 0 at each neuron. This allows the loss to back propagate through the entire network. (Brownlee, 2019)\n",
    "<br>\n",
    "<br>\n",
    "Brownlee, Jason. (2019). How to Fix the Vanishing Gradients Problem Using the ReLU. Machine Learning Mastery. https://machinelearningmastery.com/how-to-fix-vanishing-gradients-using-the-rectified-linear-activation-function/\n",
    "<br>\n",
    "<br>\n",
    "Krizhevsky, Alex. Sutskever, Ilya. Hinto, Geoffery. (2012) ImageNet Classification with Deep Convolutional neural networks. University of Toronto. http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf\n",
    "\n",
    "\n",
    "### Using the acitvation that gave the highest accuracy build 3 different models with 3 hidden layers and varying units in each hidden layer.  The first and output layers are given to you.  Use the same 'relu' activation fuction on the input and hidden layers throughout so you can compare how adding nodes and hidden layers effect your model performance with the same activation function.\n",
    "\n",
    "### By convention hidden layers are built in orders of 2^x.  For example: 2, 4, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, etc. Built three models where the nodes (units) grow, stay consistant, and decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "BTh369rD4-gr"
   },
   "outputs": [],
   "source": [
    "# First model have the nodes increase from 2\n",
    "h1_model = models.Sequential()\n",
    "h1_model.add(layers.Dense(2, activation='relu',input_shape=(28 * 28,)))\n",
    "h1_model.add(layers.Dense(4, activation='relu'))\n",
    "h1_model.add(layers.Dense(8, activation='relu'))\n",
    "h1_model.add(layers.Dense(16, activation='relu'))\n",
    "h1_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Second model have the nodes stay consistant at 512\n",
    "h2_model = models.Sequential()\n",
    "h2_model.add(layers.Dense(512, activation='relu',input_shape=(28 * 28,)))\n",
    "h2_model.add(layers.Dense(512, activation='relu'))\n",
    "h2_model.add(layers.Dense(512, activation='relu'))\n",
    "h2_model.add(layers.Dense(512, activation='relu'))\n",
    "h2_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Third model, have the nodes decrease from 2048\n",
    "h3_model = models.Sequential()\n",
    "h3_model.add(layers.Dense(2048, activation='relu',input_shape=(28 * 28,)))\n",
    "h3_model.add(layers.Dense(1024, activation='relu'))\n",
    "h3_model.add(layers.Dense(512, activation='relu'))\n",
    "h3_model.add(layers.Dense(256, activation='relu'))\n",
    "h3_model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EY-vLrzS4-g1"
   },
   "source": [
    "#### Complie the three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "AvYLN-Ld4-g3"
   },
   "outputs": [],
   "source": [
    "h1_model.compile(optimizer = 'adam',\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy'])\n",
    "\n",
    "h2_model.compile(optimizer = 'adam',\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy'])\n",
    "\n",
    "h3_model.compile(optimizer = 'adam',\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRMZ56yI4-hF"
   },
   "source": [
    "#### Fit the models with epochs = 5 and  batch_size = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "wO_mcJ9x4-hI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "400/400 [==============================] - 1s 931us/step - loss: 1.8867 - accuracy: 0.2601\n",
      "Epoch 2/5\n",
      "400/400 [==============================] - 0s 785us/step - loss: 1.3224 - accuracy: 0.4342\n",
      "Epoch 3/5\n",
      "400/400 [==============================] - 0s 768us/step - loss: 1.2090 - accuracy: 0.4764\n",
      "Epoch 4/5\n",
      "400/400 [==============================] - 0s 853us/step - loss: 1.1474 - accuracy: 0.5082\n",
      "Epoch 5/5\n",
      "400/400 [==============================] - 0s 864us/step - loss: 1.1098 - accuracy: 0.5434\n",
      "Epoch 1/5\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.2220 - accuracy: 0.9327\n",
      "Epoch 2/5\n",
      "400/400 [==============================] - 3s 9ms/step - loss: 0.0892 - accuracy: 0.9724\n",
      "Epoch 3/5\n",
      "400/400 [==============================] - 3s 9ms/step - loss: 0.0607 - accuracy: 0.9812\n",
      "Epoch 4/5\n",
      "400/400 [==============================] - 3s 8ms/step - loss: 0.0499 - accuracy: 0.9850\n",
      "Epoch 5/5\n",
      "400/400 [==============================] - 3s 9ms/step - loss: 0.0347 - accuracy: 0.9894\n",
      "Epoch 1/5\n",
      "400/400 [==============================] - 12s 30ms/step - loss: 0.1998 - accuracy: 0.9385\n",
      "Epoch 2/5\n",
      "400/400 [==============================] - 12s 30ms/step - loss: 0.0835 - accuracy: 0.9745\n",
      "Epoch 3/5\n",
      "400/400 [==============================] - 12s 30ms/step - loss: 0.0614 - accuracy: 0.9812\n",
      "Epoch 4/5\n",
      "400/400 [==============================] - 12s 30ms/step - loss: 0.0436 - accuracy: 0.9868\n",
      "Epoch 5/5\n",
      "400/400 [==============================] - 12s 29ms/step - loss: 0.0366 - accuracy: 0.9887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18914519d90>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1_model.fit(train_images, train_labels, epochs = 5, batch_size = 150)\n",
    "h2_model.fit(train_images, train_labels, epochs = 5, batch_size = 150)\n",
    "h3_model.fit(train_images, train_labels, epochs = 5, batch_size = 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x0Kcmj6x4-hU"
   },
   "source": [
    "#### Test the accuracy of the 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "uRUw9R5F4-ha"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 495us/step - loss: 1.0993 - accuracy: 0.5508\n",
      "h1_model_test_acc: 0.5508000254631042\n",
      "313/313 [==============================] - 0s 952us/step - loss: 0.0771 - accuracy: 0.9783\n",
      "h2_model_test_acc: 0.9782999753952026\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0769 - accuracy: 0.9791\n",
      "h3_model_model_model_test_acc: 0.9790999889373779\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = h1_model.evaluate(test_images, test_labels)\n",
    "print('h1_model_test_acc:', test_acc)\n",
    "\n",
    "test_loss, test_acc = h2_model.evaluate(test_images, test_labels)\n",
    "print('h2_model_test_acc:', test_acc)\n",
    "\n",
    "test_loss, test_acc = h3_model.evaluate(test_images, test_labels)\n",
    "print('h3_model_model_model_test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-fHqdpQ4-hm"
   },
   "source": [
    "#### Which model gave the highest accuracy?\n",
    "\n",
    "The constant size and decreasing 2048 model performed similarly on the test. Achieving a 97.83% and 97.91% accuracy respectively. The worst performing model was the increasing size model, which was only able to correctly identify digits 55.08% on the time. These values will change if the test is rerun do to randomness in the initialization and training of the network.</br>\n",
    "\n",
    "The performance of a model can be effected by the number of nuerons in its network. Having too many neurons may result in the model overfitting. If a model has too many neurons, it can remember the characteristics of its training data precisely. Having too few neurons results in underfitting. The limited number of neurons in the 2 neuron increasing size model most likely underfit to the training data. This resulted in the poor 55.08 percent accuracy on test. (Heaton, 2008) </br>\n",
    "\n",
    "Heaton, Jeff. (2008). <i>Introduction to Neural Networks for Java</i>. Heaton Research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "2-fHqdpQ4-hm"
   ],
   "name": "Deep_Learning_'Hello_MNIST'.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
